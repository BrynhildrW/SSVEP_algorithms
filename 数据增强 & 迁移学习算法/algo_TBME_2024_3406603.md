# 基于转移叠加理论的无监督跨个体 SSVEP 解码算法
## Calibration-free cross-subject SSVEP decoding method based on transfer superimposed theory
***

[论文链接][refer]

2024 年这篇发表在 TBME 上的论文在 SSVEP 无监督算法领域迈出了重要一步。从结构设计来看，该算法集结了两个典型要素：冲激响应-卷积模型（或者叫 transfer superimposed theory）以及原型滤波器。后者是 Lao 在 2018 年发表的一篇会议工作，在 SSVEP 算法领域沉寂了很久无人问津（可能是这段时间大家都去研究 TRCA 了）。事实证明，当传统有监督算法几乎走到尽头的当下，以原型滤波器为代表的迁移学习、数据域自适应、Zero-shot 等广义迁移算法将重回研究热门领域。

本文算法包括三个主要步骤：

（1）Source-subject transfer mode：从源域数据提取属于各受试者、各个类别的冲激响应、空间滤波器以及对应的信号模板；

（2）Global transfer mode：基于从步骤（1）中获得的滤波器计算原型滤波器（prototype spatial filter）（一维冲激响应序列视为卷积矩阵的空间滤波器）以及对应的信号模板；

（3）Ensemble classification：基于步骤（1）、（2）中获得的信号模板以及人工正余弦矩阵计算复合判别系数，对未知类别测试样本进行识别。

![算法流程图](/SSVEP_algorithms/数据增强%20&%20迁移学习算法/TBME-2024-1.png)

首先依照我的习惯定义下文中使用的基本变量符号：假设源域共有 $N_s$ 位源域受试者，且源域与目标域的刺激类别与标签设计完全相同，均有 $N_e$ 个类别的数据。简单起见，进一步假定每位源域受试者的数据样本量均相同且样本均衡（对于封装完好的公开数据集而言，这一点基本都能满足），每类刺激的样本总数为 $N_t$，导联数为 $N_c$，单试次采样点数为 $N_p$，即第 $s$ 名源域受试者的第 $k$ 类别、第 $i$ 试次的多导联数据记为 $\pmb{X}_k^{i,(s)} \in \mathbb{R}^{N_c \times N_p}$，$\pmb{X}_k^{i,(s)}$ 的试次平均记为 $\bar{\pmb{X}}_k^{(s)} \in \mathbb{R}^{N_c \times N_p}$。如无特殊说明，其它变量的上下标设定规律与之类似。目标域受试者的单试次测试信号记为 $\pmb{\mathcal{X}} \in \mathbb{R}^{N_c \times N_p}$。

---
### Part I: Source-subject transfer mode
接下来进入算法第一部分，这个过程有点类似 tlCCA 中对已知类别数据的训练建模：刺激频率为 $f_k$（单位 Hz）、采样率为 $f_s$（Hz）、采样点数为 $N_p$ 的一维 SSVEP 数据序列 $\pmb{x}_k$，其单周期响应的采样点数为 $L_k$。依照 transfer superimposed theory 可知，该数据段可分解为冲激响应（impulse response） $\pmb{r}_k \in \mathbb{R}^{1 \times L_k}$ 与卷积矩阵 $\pmb{H}_k \in \mathbb{R}^{L_k \times N_p}$ 的乘积（或 $\pmb{r}_k$ 与周期性刺激序列（periodic impulse）的卷积）：
$$
L_k = \dfrac{f_s}{f_k}, \ \ \ \ \pmb{x}_k = \pmb{r}_k \pmb{H}_k
\tag{1}
$$
上述步骤在编程实践过程中需要注意的细节在 tlCCA 专栏有所详述，这里不再阐释。总之，为了从多试次、多导联数据 $\pmb{X}_k^{(s)}$ 中提取 $\pmb{r}_k^{(s)}$，需要求解以下优化问题：
$$
\hat{\pmb{r}}_k^{(s)}, \ \ \hat{\pmb{w}}_k^{(s)} = \underset{\pmb{r}_k^{(s)}, \pmb{w}_k^{(s)}}{\arg\min} \left\| \pmb{w}_k^{(s)} \bar{\pmb{X}}_k^{(s)} - \pmb{r}_k^{(s)} \pmb{H}_k \right\|_2^2
\tag{2}
$$
上式可通过交替最小二乘法（alternating least square, ALS）求解。在第一部分中，最终获取到源域冲激响应 $\hat{\pmb{r}}_k^{(s)}\in \mathbb{R}^{1 \times L_k}$、源域空间滤波器 $\hat{\pmb{w}}_k^{(s)}\in \mathbb{R}^{N_k \times N_c}$ 以及个体性卷积模板 $\hat{\pmb{r}}_k^{(s)} \pmb{H}_k$。不失一般性地，下文将空间滤波器维度 $N_k$ 设为 1。需要注意的是，对于不同的类别（实质为刺激频率）$k$，$\hat{\pmb{r}}_k^{(s)}$ 以及 $\pmb{H}_k$ 的维度是不一样的。

---
### Part II: Global transfer mode
算法的第二部分利用原型滤波器技术集成 $N_s$ 位源域受试者的空间滤波器信息，顾名思义，从这些空间滤波器中获取到其“原型”，其本质是寻找一个与空间滤波器同维度的向量，使得该向量与各个空间滤波器的余弦相似度最大。具体而言，首先对 $\hat{\pmb{r}}_k^{(s)}$ 与 $\hat{\pmb{w}}_k^{(s)}$ 进行标准化以方便后续计算（符号改写为 $\tilde{\pmb{r}}_k^{(s)}$、$\tilde{\pmb{w}}_k^{(s)}$）：
$$
\tilde{\pmb{r}}_k^{(s)} = \dfrac{\hat{\pmb{r}}_k^{(s)}}{\left\| \hat{\pmb{r}}_k^{(s)} \right\|_2}, \ \ \ \ \tilde{\pmb{w}}_k^{(s)} = \dfrac{\hat{\pmb{w}}_k^{(s)}}{\left\| \hat{\pmb{w}}_k^{(s)} \right\|_2}
\tag{3}
$$
之后通过以下优化问题求解获得 $\tilde{\pmb{r}}_k^{(s)}$ 的原型滤波器 $\hat{\pmb{\gamma}}_k \in \mathbb{R}^{1 \times L_k}$、$\tilde{\pmb{w}}_k^{(s)}$ 的原型滤波器 $\hat{\pmb{\psi}}_k \in \mathbb{R}^{1 \times N_c}$：
$$
\begin{align}
\notag \hat{\pmb{\psi}}_k &= \underset{\pmb{\psi}_k}{\arg\max} \sum_{s=1}^{N_s} \left( \dfrac{\pmb{\psi}_k {\tilde{\pmb{w}}_k^{(s)}}^T}{\left\| \pmb{\psi}_k \right\|_2 \left\| \tilde{\pmb{w}}_k^{(s)} \right\|_2} \right)^2 = \underset{\pmb{\psi}_k}{\arg\max} \dfrac{\pmb{\psi}_k \pmb{C}_{\pmb{w}_k} {\pmb{\psi}_k}^T}{\pmb{\psi}_k {\pmb{\psi}_k}^T} , \ \ \ \ \pmb{C}_{\pmb{w}_k} = \sum_{s=1}^{N_s} {\tilde{\pmb{w}}_k^{(s)}}^T \tilde{\pmb{w}}_k^{(s)}
\notag \ \\
\notag \ \\
\notag \hat{\pmb{\gamma}}_k &= \underset{\pmb{\gamma}_k}{\arg\max} \sum_{s=1}^{N_s} \left( \dfrac{\pmb{\gamma}_k {\tilde{\pmb{r}}_k^{(s)}}^T}{\left\| \pmb{\gamma}_k \right\|_2 \left\| \tilde{\pmb{r}}_k^{(s)} \right\|_2} \right)^2 = \underset{\pmb{\gamma}_k}{\arg\max} \dfrac{\pmb{\gamma}_k \pmb{C}_{\pmb{r}_k} {\pmb{\gamma}_k}^T}{\pmb{\gamma}_k {\pmb{\gamma}_k}^T}, \ \ \ \ \pmb{C}_{\pmb{r}_k} = \sum_{s=1}^{N_s} {\tilde{\pmb{r}}_k^{(s)}}^T \tilde{\pmb{r}}_k^{(s)}
\end{align}
\tag{4}
$$
在第二部分中，最终获取到原型冲激响应 $\hat{\pmb{\gamma}}_k$ 以及原型卷积模板 $\hat{\pmb{\gamma}}_k \pmb{H}_k$。（~~作者在后续步骤中并没有使用 $\hat{\pmb{\psi}}_k$ 及相关模板，但是他们在伪代码部分却又点明需要计算 $\hat{\pmb{\psi}}_k$，可能是实际操作过程中发现 $\hat{\pmb{\psi}}_k$ 的泛化性太差？~~ 破案了，是作者公式写错了。没错，TBME 的审稿人就尼玛这样审？） 。在进入下一步之前，有必要讨论一个问题：

已知对于空间滤波器 $\tilde{\pmb{w}}_k^{(s)}$ 而言，它的维度（或者说子空间维度）$N_k$ 在不同应用场合并不总是设定成 1 的。在不同数据集中，可能 $N_k$ 设置成更大的数值会更有利于分类。另一方面，如果采用 ALS 方法迭代求解式（2），我们需要给定 $\hat{\pmb{w}}_k^{(s)}$ 的初值，此时一个合理的做法是利用现有的空间滤波器模型（如 TRCA、msCCA 等）计算获得初值。在这个过程中，我们可以获取到多个彼此正交的投影向量（即空间滤波器），每个投影向量都可以单独经由式（2）求得一种 $\hat{\pmb{r}}_k^{(s)}$。

现在问题来了，假如对于当前测试的数据集，$N_k>1$ 时分类性能最好，那么除了最大特征值对应的特征向量（即常规语境下的空间滤波器），其它特征向量对于分类是有正面作用的，按理不应该将其排除在分类模型构建之外。但是其对应的 $\hat{\pmb{r}}_k^{(s)}$ 又代表什么呢？难道是将 SSVEP 信号分解为两种频率相同、但是彼此正交的成分？这样的话和只考虑一个谐波的 CCA 过程有什么关联吗？如果将其它特征向量作为 $\hat{\pmb{w}}_k^{(s)}$ 的初值送入式（2）进行迭代，最终真的会获得与原始空间滤波器作为初值时不一样的结果吗？

之所以会有上述疑问，是因为式（2）还有另一种求法，就是把 $\bar{\pmb{X}}_k^{(s)}$ 与 $\pmb{H}_k^{(s)}$ 视为 CCA 模型输入的两个多维矩阵，利用 CCA 的方式一步到位地求解 $\hat{\pmb{r}}_k^{(s)}$ 与 $\hat{\pmb{w}}_k^{(s)}$。当使用其它特征向量作为初值进行 ALS 迭代时，最终结果会不会就是 CCA 模型中其它特征值对应的特征向量呢？

我虽然不知道上述问题的答案是什么，因为一些原因目前也不方便及时开展相关测试，不过我觉得如果能搞明白这些问题的答案，可能会有助于我们更深层次地理解 transfer superimposed theory 以及 SSVEP 的冲激响应-卷积模型。

---
### Part III: Ensemble classification
算法的最后一部分设计了三种判别系数。第一种的思路是利用不同源域受试者的卷积模板 $\pmb{r}_k^{(s)} \pmb{H}_k^{(s)}$ 与标准化空间滤波器 $\tilde{\pmb{w}}_k^{(s)}$，对测试数据 $\pmb{\mathcal{X}}$ 按不同受试者、不同类别依次进行匹配并集成；第二种的思路是利用原型滤波器 $\hat{\pmb{\psi}}_k$ 处理测试数据 $\pmb{\mathcal{X}}$，并与原型卷积模板 $\hat{\pmb{\gamma}}_k \pmb{H}_k$ 进行匹配；第三种是普通 CCA 模型：
$$
\begin{align}
\notag \rho_{k,1} &= \dfrac{1}{N_s} \sum_{s=1}^{N_s} {\rm corr} \left( \tilde{\pmb{w}}_k^{(s)} \pmb{\mathcal{X}}, \ \ \pmb{r}_k^{(s)} \pmb{H}_k^{(s)} \right)\\
\notag \ \\
\notag \rho_{k,2} &= {\rm corr} \left( \hat{\pmb{\psi}}_k \pmb{\mathcal{X}}, \ \ \hat{\pmb{\gamma}}_k \pmb{H}_k \right)\\
\notag \ \\
\notag \rho_{k,3} &= {\rm CCA} \left( \pmb{\mathcal{X}}, \ \ \pmb{Y}_k \right)\\
\end{align}
\tag{5}
$$
三种系数用常规方法进行集成：
$$
\rho_k = \sum_{i=1}^{3} {\rm sign} (\rho_{k,i}) {\rho_{k,i}}^2
\tag{6}
$$
到这里，该算法的过程已经介绍完毕了。我还想再结合论文结果分析一下算法的性能。文中测试了式（5）中三种系数的分类性能：

![三种系数性能](/SSVEP_algorithms/数据增强%20&%20迁移学习算法/TBME-2024-2.png)

毫无疑问，三种都用（Fusion feature）的情况下分类性能最好。这里有几点讨论想与读者们分享：

（1）这个测试并非是某种“消融实验”，其中的 Correlation feature 1~3 分别表示式（5）中的三个系数，而正经消融实验应该是去掉某个因素之后观察测试结果。因此本文提供的结果只能展示每个弱分类器各自的性能，至于融合分类器中哪一项因素起到了更重要的作用，单独通过弱分类器自身的表现是得不出有效结论的；

（2）Correlation 3 就是普通的 CCA（或 FBCCA）系数。在 BETA 数据集中，当数据时长超过 1 秒时，CCA 居然成了集成模型中的强分类器；大多数情况下，Correlation 1 是最弱的分类器。这一点不难理解，毕竟 $\tilde{\pmb{w}}_k^{(s)}$ 与 $\pmb{r}_k^{(s)} \pmb{H}_k^{(s)}$ 都只包含了源域受试者个体的信息，从某种意义上讲，Correlation 1 非常考验目标域受试者与源域受试者的信息相似度。在其它 domain adaptation 算法中，通常会加入一些目标域的数据，从而训练一种从源域到目标域的迁移模式，减少 domain gap。

（3）Correlation 1 还存在一个潜在的问题，这一点在文中的 discussion 部分也有提及，就是源域受试者的选择。作者并没有在论文中明确给出每个目标域受试者对应的源域受试者清单，他们说重复测试 20 次，每次都是 randomly selected，真 randomly 就有鬼咯。以 Benchmark 数据集为例，总共 35 位受试者，选用其中 20 位受试者共有几种可能？$C_{35}^{20}$，这是远超 20 次的、无法遍历的天文数字。想也知道为了发论文肯定是根据某些条件筛选了一下，只不过作者团队确实目前还没有总结出一套具有说服力的可行方案，因此才会把这个结论加进 discussion 里。

（4）在三种系数中，Correlation 2 不总是最佳的，但它基本上是最稳定的，尤其在数据时长比较短的时候。如果作者真的进行了消融实验，恐怕把 Correlation 2 去掉的话这个模型就要解体了。










[refer]: https://ieeexplore.ieee.org/document/10632864/
